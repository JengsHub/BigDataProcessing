{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning models in PySpark\n",
    "\n",
    "## Data Loading and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requried packages to initiate spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# Setting application name and number of working processors\n",
    "conf = SparkConf().setAppName(\"Assignment 2\").setMaster(\"local[*]\").set('spark.sql.session.timeZone', 'UTC')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Defining the schema\n",
    "pedestrian_schema = StructType([\n",
    "    StructField('ID', IntegerType(), True),\n",
    "    StructField('Date_Time', TimestampType(), True),\n",
    "    StructField('Year', IntegerType(), True),\n",
    "    StructField('Month', StringType(), True),\n",
    "    StructField('Mdate', IntegerType(), True),\n",
    "    StructField('Day', StringType(), True),\n",
    "    StructField('Time', IntegerType(), True),\n",
    "    StructField('Sensor_ID', IntegerType(), True),\n",
    "    StructField('Sensor_Name', StringType(), True),\n",
    "    StructField('Hourly_Counts', IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pedestrian count csv files into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file\n",
    "pedestrian_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .schema(pedestrian_schema)\\\n",
    "    .option(\"timestampFormat\", \"M/d/y h:m:s a\")\\\n",
    "    .load(\"Pedestrian_Counting_System_-_Monthly__counts_per_hour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date_Time: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Mdate: integer (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Time: integer (nullable = true)\n",
      " |-- Sensor_ID: integer (nullable = true)\n",
      " |-- Sensor_Name: string (nullable = true)\n",
      " |-- Hourly_Counts: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking schema of the read file\n",
    "pedestrian_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+\n",
      "|     ID|          Date_Time|Year|   Month|Mdate|   Day|Time|Sensor_ID|         Sensor_Name|Hourly_Counts|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+\n",
      "|2887628|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       34|Flinders St-Spark La|          300|\n",
      "|2887629|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       39|        Alfred Place|          604|\n",
      "|2887630|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       37|     Lygon St (East)|          216|\n",
      "|2887631|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       40|Lonsdale St-Sprin...|          627|\n",
      "|2887632|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       36|     Queen St (West)|          774|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking example datas of the read file\n",
    "pedestrian_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an additional column “above_threshold”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Creating the column named above_threshold based on hourly counts\n",
    "pedestrian_df = pedestrian_df.withColumn(\"above_threshold\", when(pedestrian_df[\"Hourly_Counts\"] >= 2000, 1.00).otherwise(0.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date_Time: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Mdate: integer (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Time: integer (nullable = true)\n",
      " |-- Sensor_ID: integer (nullable = true)\n",
      " |-- Sensor_Name: string (nullable = true)\n",
      " |-- Hourly_Counts: integer (nullable = true)\n",
      " |-- above_threshold: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pedestrian_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+\n",
      "|     ID|          Date_Time|Year|   Month|Mdate|   Day|Time|Sensor_ID|         Sensor_Name|Hourly_Counts|above_threshold|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+\n",
      "|2887628|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       34|Flinders St-Spark La|          300|            0.0|\n",
      "|2887629|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       39|        Alfred Place|          604|            0.0|\n",
      "|2887630|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       37|     Lygon St (East)|          216|            0.0|\n",
      "|2887631|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       40|Lonsdale St-Sprin...|          627|            0.0|\n",
      "|2887632|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       36|     Queen St (West)|          774|            0.0|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pedestrian_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to store columns based on type\n",
    "df_types = pedestrian_df.dtypes\n",
    "num_cols = []\n",
    "# Store columns of type integer\n",
    "for x,y in df_types:\n",
    "    if y == \"int\":\n",
    "        num_cols.append(x)\n",
    "\n",
    "        # Using describe to get the basic statistics of numerical datas\n",
    "basic_statistics = pedestrian_df[num_cols]\n",
    "basic_stats = basic_statistics.describe()\n",
    "stats = basic_statistics.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mdate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sensor_ID</th>\n",
       "      <th>Hourly_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3435106</td>\n",
       "      <td>3435106</td>\n",
       "      <td>3435106</td>\n",
       "      <td>3435106</td>\n",
       "      <td>3435106</td>\n",
       "      <td>3435106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1717553.5</td>\n",
       "      <td>2016.0032330880038</td>\n",
       "      <td>15.751918863639142</td>\n",
       "      <td>11.459955238644746</td>\n",
       "      <td>22.978422791028866</td>\n",
       "      <td>560.7805942524044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>991629.8312350252</td>\n",
       "      <td>3.1237869143646275</td>\n",
       "      <td>8.79918757461428</td>\n",
       "      <td>6.943473866829414</td>\n",
       "      <td>16.229792156265397</td>\n",
       "      <td>809.9942576353371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>3435106</td>\n",
       "      <td>2020</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "      <td>15979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25%</td>\n",
       "      <td>858777.25</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50%</td>\n",
       "      <td>1717553.5</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75%</td>\n",
       "      <td>2576329.75</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 ID                Year               Mdate  \\\n",
       "0   count            3435106             3435106             3435106   \n",
       "1    mean          1717553.5  2016.0032330880038  15.751918863639142   \n",
       "2  stddev  991629.8312350252  3.1237869143646275    8.79918757461428   \n",
       "3     min                  1                2009                   1   \n",
       "4     max            3435106                2020                  31   \n",
       "5     25%          858777.25              2014.0                 8.0   \n",
       "6     50%          1717553.5              2016.0                16.0   \n",
       "7     75%         2576329.75              2019.0                23.0   \n",
       "\n",
       "                 Time           Sensor_ID      Hourly_Counts  \n",
       "0             3435106             3435106            3435106  \n",
       "1  11.459955238644746  22.978422791028866  560.7805942524044  \n",
       "2   6.943473866829414  16.229792156265397  809.9942576353371  \n",
       "3                   0                   1                  0  \n",
       "4                  23                  71              15979  \n",
       "5                 5.0                 9.0               50.0  \n",
       "6                11.0                19.0              210.0  \n",
       "7                17.0                34.0              721.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Creating lists for each numerical columns\n",
    "ID = []\n",
    "Year = []\n",
    "Mdate = []\n",
    "Time = []\n",
    "Sensor = []\n",
    "Hourly_Count = []\n",
    "\n",
    "for row in stats:\n",
    "    ID.append(row[\"ID\"])\n",
    "    Year.append(row[\"Year\"])\n",
    "    Mdate.append(row[\"Mdate\"])\n",
    "    Time.append(row[\"Time\"])\n",
    "    Sensor.append(row[\"Sensor_ID\"])\n",
    "    Hourly_Count.append(row[\"Hourly_Counts\"])\n",
    "\n",
    "percentiles = [25, 50, 75]\n",
    "perc_list = []\n",
    "\n",
    "# using the numpy package, calculate the percentile for numerical columns\n",
    "for perc in percentiles:\n",
    "    id_per = np.percentile(ID, perc)\n",
    "    yr_per = np.percentile(Year, perc)\n",
    "    mdt_per = np.percentile(Mdate, perc)\n",
    "    tim_per = np.percentile(Time, perc)\n",
    "    sen_per = np.percentile(Sensor, perc)\n",
    "    hco_per = np.percentile(Hourly_Count, perc)\n",
    "    perc_list.append(Row((str(perc)+\"%\"), str(id_per), str(yr_per), str(mdt_per), str(tim_per), str(sen_per), str(hco_per)))\n",
    "    \n",
    "percSchema = StructType([       \n",
    "    StructField('summary', StringType(), True),\n",
    "    StructField('ID', StringType(), True),\n",
    "    StructField('Year', StringType(), True),\n",
    "    StructField('Mdate', StringType(), True),\n",
    "    StructField('Time', StringType(), True),\n",
    "    StructField('Sensor_ID', StringType(), True),\n",
    "    StructField('Hourly_Counts', StringType(), True)\n",
    "])\n",
    "\n",
    "perc_df = spark.createDataFrame(data=perc_list, schema = percSchema)\n",
    "\n",
    "# Union the percentile dataframe with the result from .describe() method\n",
    "statistics = basic_stats.union(perc_df)\n",
    "statistics.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the count of above threshold column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the count for above and below threshold values:\n",
      "Above:  250942\n",
      "Below:  3184164\n"
     ]
    }
   ],
   "source": [
    "above = pedestrian_df.filter(pedestrian_df[\"above_threshold\"] == \"1\").count()\n",
    "below = pedestrian_df.filter(pedestrian_df[\"above_threshold\"] == \"0\").count()\n",
    "\n",
    "print(\"These are the count for above and below threshold values:\")\n",
    "print(\"Above: \", str(above))\n",
    "print(\"Below: \", str(below))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is a class imbalance going on. The dataset is skewed such that the above to below ratio is roughly 1:12. In a imbalanced/skewed datset, the machine learning model might overfit to the class that is more respresented in our data set, in this case, the \"below\" threshold. This might cause the machine learning model to fail when placed into real life usage. For example, in our case, the model can just keep predicting that the hourly count will be below threshold everytime and get a good accuracy score as the chances of hourly counts being above threshold is low. However this same model might fail when its actually placed in \"real world\" situation where it might be expected to deal with well balanced real time data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and ML training\n",
    "\n",
    "## Preparing Spark ML Transformers/Estimators for features, labels and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, dayofweek, weekofyear\n",
    "\n",
    "# DDing the additional columns for month, day of week and week of year\n",
    "pedestrian_df = pedestrian_df.withColumn(\"Month\", month(pedestrian_df[\"Date_Time\"]))\n",
    "pedestrian_df = pedestrian_df.withColumn(\"day_of_week\", dayofweek(pedestrian_df[\"Date_Time\"]))\n",
    "pedestrian_df = pedestrian_df.withColumn(\"week_of_year\", weekofyear(pedestrian_df[\"Date_Time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date_Time: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Mdate: integer (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Time: integer (nullable = true)\n",
      " |-- Sensor_ID: integer (nullable = true)\n",
      " |-- Sensor_Name: string (nullable = true)\n",
      " |-- Hourly_Counts: integer (nullable = true)\n",
      " |-- above_threshold: double (nullable = false)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- week_of_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pedestrian_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------+\n",
      "|Month|day_of_week|week_of_year|\n",
      "+-----+-----------+------------+\n",
      "|   11|          6|          44|\n",
      "|   11|          6|          44|\n",
      "|   11|          6|          44|\n",
      "|   11|          6|          44|\n",
      "|   11|          6|          44|\n",
      "+-----+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pedestrian_df[\"Month\", \"day_of_week\", \"week_of_year\"].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Mdate</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sensor_ID</th>\n",
       "      <th>Sensor_Name</th>\n",
       "      <th>Hourly_Counts</th>\n",
       "      <th>above_threshold</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "      <td>1388451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1856380.176237404</td>\n",
       "      <td>2016.7631367617582</td>\n",
       "      <td>6.626148852210124</td>\n",
       "      <td>15.736916174931633</td>\n",
       "      <td>None</td>\n",
       "      <td>15.999957506602682</td>\n",
       "      <td>24.93814185736479</td>\n",
       "      <td>None</td>\n",
       "      <td>855.0832171967178</td>\n",
       "      <td>0.11952024234200559</td>\n",
       "      <td>4.00004969566805</td>\n",
       "      <td>27.01301594366672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>641221.2897014186</td>\n",
       "      <td>1.6902188308840698</td>\n",
       "      <td>3.4430627097752864</td>\n",
       "      <td>8.798087424359263</td>\n",
       "      <td>None</td>\n",
       "      <td>4.320488603233932</td>\n",
       "      <td>15.201145123230535</td>\n",
       "      <td>None</td>\n",
       "      <td>906.5378513311169</td>\n",
       "      <td>0.3243997993306639</td>\n",
       "      <td>2.0005723183741915</td>\n",
       "      <td>15.037502299412996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>745919</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Alfred Place</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2966838</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "      <td>Webb Bridge</td>\n",
       "      <td>15979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 ID                Year               Month  \\\n",
       "0   count            1388451             1388451             1388451   \n",
       "1    mean  1856380.176237404  2016.7631367617582   6.626148852210124   \n",
       "2  stddev  641221.2897014186  1.6902188308840698  3.4430627097752864   \n",
       "3     min             745919                2014                   1   \n",
       "4     max            2966838                2019                  12   \n",
       "\n",
       "                Mdate        Day                Time           Sensor_ID  \\\n",
       "0             1388451    1388451             1388451             1388451   \n",
       "1  15.736916174931633       None  15.999957506602682   24.93814185736479   \n",
       "2   8.798087424359263       None   4.320488603233932  15.201145123230535   \n",
       "3                   1     Friday                   9                   1   \n",
       "4                  31  Wednesday                  23                  62   \n",
       "\n",
       "    Sensor_Name      Hourly_Counts      above_threshold         day_of_week  \\\n",
       "0       1388451            1388451              1388451             1388451   \n",
       "1          None  855.0832171967178  0.11952024234200559    4.00004969566805   \n",
       "2          None  906.5378513311169   0.3243997993306639  2.0005723183741915   \n",
       "3  Alfred Place                  0                  0.0                   1   \n",
       "4   Webb Bridge              15979                  1.0                   7   \n",
       "\n",
       "         week_of_year  \n",
       "0             1388451  \n",
       "1   27.01301594366672  \n",
       "2  15.037502299412996  \n",
       "3                   1  \n",
       "4                  53  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering data between 2014 to 2019 only for hours between 9am to 11pm\n",
    "# Filter from 2014 to 2019 first\n",
    "pedes_df_14_19 = pedestrian_df.filter((pedestrian_df[\"Year\"] >= 2014) & (pedestrian_df[\"Year\"] <= 2019))\n",
    "\n",
    "#Filter from 9am to 11pm\n",
    "pedes_df_14_19 = pedes_df_14_19.filter((pedes_df_14_19[\"Time\"] >= 9) & (pedes_df_14_19[\"Time\"] <= 23))\n",
    "\n",
    "pedes_df_14_19.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning parameters, this might take some time to run\n",
    "\n",
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator,CrossValidatorModel\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# # Create ParamGrid for Cross Validation\n",
    "\n",
    "# (train, test) = pedes_df_14_19.randomSplit([0.8, 0.2], seed=202)\n",
    "\n",
    "# dt_pipeline = Pipeline(stages=[encoder, assembler, dt])\n",
    "# train = train.withColumnRenamed('above_threshold', 'label')\n",
    "\n",
    "# # hello = trans_pipeline.fit(train)\n",
    "\n",
    "# dtparamGrid = (ParamGridBuilder()\n",
    "#              .addGrid(dt.maxDepth, [1, 2, 3])\n",
    "#              .addGrid(dt.maxBins, [2, 3, 5])\n",
    "#              .build())\n",
    "\n",
    "# dtevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# dtcv = CrossValidator(estimator = dt_pipeline,\n",
    "#                       estimatorParamMaps = dtparamGrid,\n",
    "#                       evaluator = dtevaluator,\n",
    "#                       numFolds = 3)\n",
    "\n",
    "# dtcvModel = dtcv.fit(train)\n",
    "\n",
    "# bestModel= dtcvModel.bestModel\n",
    "# print(bestModel.stages)\n",
    "# print('Best Param for DT: ', bestModel.stages[-1]._java_obj.paramMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write code for tranformers/estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Using OHE on sensorID as sensorID is unique and should play no ordinal role\n",
    "in_OHE = [\"Sensor_ID\"]\n",
    "out_OHE = [\"Sensor_ID_vec\"]\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=in_OHE, outputCols=out_OHE).setHandleInvalid(\"keep\")\n",
    "\n",
    "in_features_vec = [\"Month\", \"Mdate\", \"week_of_year\", \"day_of_week\", \"Time\"] + out_OHE\n",
    "\n",
    "assembler = VectorAssembler(inputCols = in_features_vec, outputCol = \"features\")\n",
    "\n",
    "# Creating ML model estimators for Three ML methods, Logistic Regression, Decision Tree, Random Forest\n",
    "lr = LogisticRegression(labelCol='label', featuresCol='features', maxIter=100, regParam = 0.0001)\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 4, maxBins = 3)\n",
    "rf = RandomForestClassifier(labelCol='label', featuresCol='features', numTrees=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "lr_pipeline = Pipeline(stages=[encoder, assembler, lr])\n",
    "dt_pipeline = Pipeline(stages=[encoder, assembler, dt])\n",
    "rf_pipeline = Pipeline(stages=[encoder, assembler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedes_df_14_19 = pedes_df_14_19.withColumnRenamed('above_threshold', 'label')\n",
    "\n",
    "# Creating train and testing data set\n",
    "train = pedes_df_14_19.filter((pedes_df_14_19[\"Year\"] >= 2014) & (pedes_df_14_19[\"Year\"] <= 2018))\n",
    "test = pedes_df_14_19.filter(pedes_df_14_19[\"Year\"] == 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating models\n",
    "### Train Model and  Performing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr_pipeline.fit(train)\n",
    "dt_model = dt_pipeline.fit(train)\n",
    "rf_model = rf_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform predictions on test\n",
    "lr_predictions = lr_model.transform(test)\n",
    "dt_predictions = dt_model.transform(test)\n",
    "rf_predictions = rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Measure classification performance\n",
    "# Logistic Regression Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+------+\n",
      "|above_threshold|prediction| count|\n",
      "+---------------+----------+------+\n",
      "|            1.0|       1.0| 11186|\n",
      "|            0.0|       1.0|  7949|\n",
      "|            1.0|       0.0| 19855|\n",
      "|            0.0|       0.0|246542|\n",
      "+---------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_predictions.withColumnRenamed('label', 'above_threshold')\n",
    "lr_predictions.groupBy('above_threshold', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model statistics:\n",
      "Accuracy:  0.9026238740316321\n",
      "Recall:  0.36036210173641314\n",
      "Precision:  0.5845832244577999\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "for_eval_lr = lr_predictions.select(\"prediction\", \"above_threshold\").collect()\n",
    "\n",
    "pre_and_label_lr = sc.parallelize(for_eval_lr)\n",
    "\n",
    "lr_metrics = MulticlassMetrics(pre_and_label_lr)\n",
    "\n",
    "print(\"Logistic Regression Model statistics:\")\n",
    "print(\"Accuracy: \", str(lr_metrics.accuracy))\n",
    "print(\"Recall: \", str(lr_metrics.recall(1.0)))\n",
    "print(\"Precision: \", str(lr_metrics.precision(1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+------+\n",
      "|above_threshold|prediction| count|\n",
      "+---------------+----------+------+\n",
      "|            1.0|       1.0|  4549|\n",
      "|            0.0|       1.0|  2421|\n",
      "|            1.0|       0.0| 26492|\n",
      "|            0.0|       0.0|252070|\n",
      "+---------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_predictions = dt_predictions.withColumnRenamed('label', 'above_threshold')\n",
    "dt_predictions.groupBy('above_threshold', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model statistics:\n",
      "Accuracy:  0.8987398960536822\n",
      "Recall:  0.14654811378499405\n",
      "Precision:  0.6526542324246772\n"
     ]
    }
   ],
   "source": [
    "for_eval_dt = dt_predictions.select(\"prediction\", \"above_threshold\").collect()\n",
    "\n",
    "pre_and_label_dt = sc.parallelize(for_eval_dt)\n",
    "\n",
    "dt_metrics = MulticlassMetrics(pre_and_label_dt)\n",
    "\n",
    "print(\"Decision Tree Model statistics:\")\n",
    "print(\"Accuracy: \", str(dt_metrics.accuracy))\n",
    "print(\"Recall: \", str(dt_metrics.recall(1.0)))\n",
    "print(\"Precision: \", str(dt_metrics.precision(1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+------+\n",
      "|above_threshold|prediction| count|\n",
      "+---------------+----------+------+\n",
      "|            1.0|       1.0|  4300|\n",
      "|            0.0|       1.0|  2270|\n",
      "|            1.0|       0.0| 26741|\n",
      "|            0.0|       0.0|252221|\n",
      "+---------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf_predictions.withColumnRenamed('label', 'above_threshold')\n",
    "rf_predictions.groupBy('above_threshold', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model statistics:\n",
      "Accuracy:  0.8983966770799771\n",
      "Recall:  0.138526464997906\n",
      "Precision:  0.654490106544901\n"
     ]
    }
   ],
   "source": [
    "for_eval_rf = rf_predictions.select(\"prediction\", \"above_threshold\").collect()\n",
    "\n",
    "pre_and_label_rf = sc.parallelize(for_eval_rf)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(pre_and_label_rf)\n",
    "\n",
    "print(\"Random Forest Model statistics:\")\n",
    "print(\"Accuracy: \", str(rf_metrics.accuracy))\n",
    "print(\"Recall: \", str(rf_metrics.recall(1.0)))\n",
    "print(\"Precision: \", str(rf_metrics.precision(1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts and Persisting the best model\n",
    "According to the metrics, the better model in my case appears to be the logistic regression model. The overall scores for the logistic regression metric seems to be higher than the others. For random forest, it has a high accuracy score, but the recall and precision score is lower comapred to the rest. As for the Decision Tree metric, its score are similar to that of Logistic Regression, but the recall score is around 2 times lower than that of logistic regression. Logistic Regression metric might not have the best performance for some of the metric scores, but on average it seems to have a better overall score when compared to the rest. Therefore, the logistic regression model is persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\tLogisticRegression_8fe6a33dbe10-featuresCol: features,\n",
      "\tLogisticRegression_8fe6a33dbe10-labelCol: label,\n",
      "\tLogisticRegression_8fe6a33dbe10-maxIter: 100,\n",
      "\tLogisticRegression_8fe6a33dbe10-regParam: 1.0E-4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "lr_model.write().overwrite().save('pedestrian_count_logistic_regression_models')\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "pipelineModel = PipelineModel.load('pedestrian_count_logistic_regression_models')\n",
    "print(pipelineModel.stages[-1]._java_obj.paramMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write code to print out the leaf node splitting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtModel = dt_pipeline.fit(train)\n",
    "va = dtModel.stages[-2]\n",
    "tree = dtModel.stages[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print leaf node splitting Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_1f47bacc6ece, depth=4, numNodes=17, numClasses=2, numFeatures=64\n",
      "  If (feature 43 in {1.0})\n",
      "   If (feature 4 <= 18.5)\n",
      "    Predict: 1.0\n",
      "   Else (feature 4 > 18.5)\n",
      "    If (feature 3 <= 5.5)\n",
      "     If (feature 0 <= 4.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 0 > 4.5)\n",
      "      Predict: 0.0\n",
      "    Else (feature 3 > 5.5)\n",
      "     Predict: 1.0\n",
      "  Else (feature 43 not in {1.0})\n",
      "   If (feature 9 in {1.0})\n",
      "    If (feature 4 <= 18.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 4 > 18.5)\n",
      "     Predict: 0.0\n",
      "   Else (feature 9 not in {1.0})\n",
      "    If (feature 8 in {1.0})\n",
      "     If (feature 4 <= 18.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 4 > 18.5)\n",
      "      Predict: 0.0\n",
      "    Else (feature 8 not in {1.0})\n",
      "     Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print top 3 features and their corresponding feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 , Time :  0.15118188175825525\n",
      "Feature 2 , day_of_week :  0.009186798183601566\n",
      "Feature 3 , Month :  0.000793353004851594\n"
     ]
    }
   ],
   "source": [
    "top_3_feats = list(zip(va.getInputCols(), tree.featureImportances))\n",
    "\n",
    "top_3_feats = sorted(top_3_feats, key=lambda tup:(-tup[1], tup[0]))\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Feature\", str(i+1), \",\", top_3_feats[i][0], \": \" , str(top_3_feats[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
